# 关系

人工智能、机器学习和深度学习之间的关系

![3者关系](./images/Deep_Learning_Icons_R5_PNG.png)

## 机器学习：一种实现人工智能的方法

机器学习：通过计算机，对一部分数据进行学习，然后对另外一些数据进行预测或判断。

机器学习的核心是
> 使用算法解析数据，从中学习，然后对新数据做出决定或预测。

也就是说，计算机利用可获取的数据得出某一模型，然后利用此模型进行预测的一种方法，这个过程跟人的学习过程有些类似，比如人获取一定的经验，可以对新问题进行预测。

我们举个例子，支付宝的“集五福”活动，我们用手机扫有“福”字的照片，识别福字，这个就是用了机器学习的方法。我们可以为计算机提供“福”字的照片数据，通过算法、模型、机型训练，计算机不断更新学习，然后输入一张新的福字照片，机器自动识别这张照片上是否有福字。

机器学习的概念来自早期的人工智能研究者。机器学习，是一门多领域交叉学科，涉及概率论、统计学、计算机科学等多门学科。已经研究出的算法包括决策树、聚类、支持向量机、线性回归、逻辑回归、EM（最大期望）、增强学习和贝叶斯网络等。机器学习的概念就是通过输入海量训练数据对模型进行训练，使模型掌握数据所蕴含的潜在规律，进而对新输入的数据进行准确的分类或预测。与传统的使用特定指令集手写软件不同，我们使用大量数据和算法来“训练”机器，由此带来机器学习如何完成任务。如下图所示：

![机器学习](./images/MachineLearning.jpeg)

从学习方法上来分，机器学习算法可以分为监督学习（如分类问题）、无监督学习（如聚类问题）、半监督学习、强化学习和深度学习。

### 机器学习分类：

### （1）监督学习

监督学习，利用一组已知类别的样本，调整分类器的参数，使其达到所要求性能的过程。

监督学习就是通过对数据样本因子和已知的结果建立联系，提取特征值和映射关系，通过已知的结果，已知数据样本不断的学习和训练，对新的数据进行结果的预测。

监督学习通常用在分类和回归。比如手机识别垃圾短信，电子邮箱识别垃圾邮件，都是通过对一些历史短信、历史邮件做垃圾分类的标记，对这些带有标记的数据进行模型训练，然后获取到新的短信或是新的邮件时，进行模型匹配，来识别此邮件是或是不是，这就是监督学习下分类的预测。

再举一个回归的例子，比如我们要预测公司净利润的数据，我们可以通过历史上公司利润（目标值），以及跟利润相关的指标，比如营业收入、资产负债情况、管理费用等数据，通过回归的方式我们回到的一个回归方程，建立公司利润与相关因此的方程式，通过输入因子数据，来预测公司利润。

监督学习难点是获取具有目标值的样本数据，成本较高，成本高的原因在于这些训练集的要依赖人工标注工作。

### （2）无监督学习

无监督学习跟监督学习的区别就是选取的样本数据无需有目标值，我们无需分析这些数据对某些结果的影响，只是分析这些数据内在的规律。

无监督学习常用在聚类分析上面。比如客户分群、因子降维等。比如RFM模型的使用，通过客户的销售行为（消费次数、最近消费时间、消费金额）指标，来对客户数据进行聚类：

- 重要价值客户：最近消费时间近、消费频次和消费金额都很高；
- 重要保持客户：最近消费时间较远，但消费频次和金额都很高，说明这是个一段时间没来的忠诚客户，我们需要主动和他保持联系；
- 重要发展客户：最近消费时间较近、消费金额高，但频次不高，忠诚度不高，很有潜力的用户，必须重点发展；
- 重要挽留客户：最近消费时间较远、消费频次不高，但消费金额高的用户，可能是将要流失或者已经要流失的用户，应当基于挽留措施。

除此之外，无监督学习也适用于降维，无监督学习比监督学习好处是数据不需要人工打标记，数据获取成本低。

### （3）半监督学习

半监督学习是监督学习和无监督学习相互结合的一种学习方法，通过半监督学习的方法可以实现分类、回归、聚类的结合使用。

半监督分类：是在无类标签的样例的帮助下训练有类标签的样本，获得比只用有类标签的样本训练得到更优的分类；

半监督回归：在无输出的输入的帮助下训练有输出的输入，获得比只用有输出的输入训练得到的回归器性能更好的回归；

半监督聚类：在有类标签的样本的信息帮助下获得比只用无类标签的样例得到的结果更好的簇，提高聚类方法的精度；

半监督降维：在有类标签的样本的信息帮助下找到高维输入数据的低维结构，同时保持原始高维数据和成对约束的结构不变。

半监督学习是最近比较流行的方法。

### （4）强化学习

强化学习是一种比较复杂的机器学习方法，强调系统与外界不断的交互反馈，它主要是针对流程中不断需要推理的场景，比如无人汽车驾驶，它更多关注性能。它是机器学习中的热点学习方法。

### （5）**深度学习：一种实现机器学习的方法**

深度学习是实现机器学习的一种方法。属于机器学习的子类。

早期机器学习研究者中还开发了一种叫人工神经网络的算法，但是发明之后数十年都默默无闻。神经网络是受人类大脑的启发而来的：神经元之间的相互连接关系。是利用深度神经网络来解决特征表达的一种学习过程。但是，人类大脑中的神经元可以与特定范围内的任意神经元连接，而人工神经网络中数据传播要经历不同的层，传播方向也不同。

举个例子，你可以将一张图片切分为小块，然后输入到神经网络的第一层中。在第一层中做初步计算，然后神经元将数据传至第二层。由第二层神经元执行任务，依次类推，直到最后一层，然后输出最终的结果。

每个神经元都会给其输入指定一个权重：相对于执行的任务该神经元的正确和错误程度。最终的输出由这些权重共同决定。

不过，问题在于即使是最基础的神经网络也要耗费巨大的计算资源，因此当时不算是一个可行的方法。不过，以多伦多大学 Geoffrey Hinton 教授为首的一小批狂热研究者们坚持采用这种方法，最终让超级计算机能够并行执行该算法，并证明该算法的作用。

如今，在某些情况下，通过深度学习训练过的机器在图像识别上表现优于人类，这包括找猫、识别血液中的癌症迹象等。谷歌的 AlphaGo 学会了围棋，并为比赛进行了大量的训练：不断的和自己比赛。

深度学习归根结底也是机器学习，不过它不同于监督学习、半监督学习、无监督学习、强化学习的这种分类方法，它是另一种分类方法，基于算法神经网络的深度，可以分成浅层学习算法和深度学习算法。

浅层学习算法主要是对一些结构化数据、半结构化数据一些场景的预测，深度学习主要解决复杂的场景，比如图像、文本、语音识别与分析等。

深度学习本来并不是一种独立的学习方法，其本身也会用到有监督和无监督的学习方法来训练深度神经网络。

但由于近几年该领域发展迅猛，一些特有的学习手段相继被提出（如残差网络），因此越来越多的人将其单独看作一种学习的方法。

深度学习，作为目前最热的机器学习方法，但并不意味着是机器学习的终点。

起码目前存在以下问题：

1. 深度学习模型需要大量的训练数据，才能展现出神奇的效果，但现实生活中往往会遇到小样本问题，此时深度学习方法无法入手，传统的机器学习方法就可以处理；
2. 有些领域，采用传统的简单的机器学习方法，可以很好地解决了，没必要非得用复杂的深度学习方法；
3. 深度学习的思想，来源于人脑的启发，但绝不是人脑的模拟，举个例子，给一个三四岁的小孩看一辆自行车之后，再见到哪怕外观完全不同的自行车，小孩也十有八九能做出那是一辆自行车的判断，也就是说，人类的学习过程往往不需要大规模的训练数据，而现在的深度学习方法显然不是对人脑的模拟。

深度学习大佬 Yoshua Bengio 在 Quora 上回答一个类似的问题时，有一段话讲得特别好，这里引用一下，以回答上述问题：

> Science is NOT a battle, it is a collaboration. We all build on each other's ideas. Science is an act of love, not war. Love for the beauty in the world that surrounds us and love to share and build something together. That makes science a highly satisfying activity, emotionally speaking!

这段话的大致意思是，科学不是战争而是合作，任何学科的发展从来都不是一条路走到黑，而是同行之间互相学习、互相借鉴、博采众长、相得益彰，站在巨人的肩膀上不断前行。机器学习的研究也是一样，你死我活那是邪教，开放包容才是正道。

结合机器学习2000年之后的发展，再来看Bengio的这段话，深有感触。进入21世纪，纵观机器学习发展历程，研究热点可以简单总结为2000-2006年的流形学习、2006年-2011年的稀疏学习、2012年至今的深度学习。
